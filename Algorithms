Algorithms - Steps to be performed for accomplishing a particular task.
Real time example: Steps involved in Preparing Tea.

Need for Big O Notation:

Same implementation can take different time when it is run on Super Computer and Normal Computer.
Hence for determing performance based on number of steps Big O Notation was introduced, where performance is measured by taking 
number of steps into account.

Big O Notation -
Determines performance of the data structures
Describes the complexity of the data structure
Tells us how well an algorithm scales as the input increases.
Worst case is used to determine the time complexity of the algorithm.

O(1) - Constant time - No matter how many elements u have in your data structures, Algorithm always perform same number of operations
O(logn)(base 2) - Logarithamic - Slows rises as the number of elements increases Ex: Binary Search
O(n) - Linear - Descreases the performance as the elements decreases. Ex: For Loop, While Loop
O(nlogn)(base 2) - n log-star-n Logarithamic - Slows rises as the number of elements increases Ex: Binary Search
O(n^2) - Quadratic - As the number of elements increase, performance becomes very very low. Ex: Loop within loop
O(c^n) - Exponential - Recusrive calls over n and loop over c in it.
O(n!) - Factorial - Looping over n and recursive call in the loop for (n-1) elements

Sort Algorithms:

Bubble Sort 
  - Performance degrades quickly as number of elements grows.
  - Grows the sorted partition from right to left
Algorithm:
  - Larger value in an array bubbles up to the top on each iteration.
  - During each iteration, an element is compared with the next one and swaped if an element is greater than the next one.
  - End of each iteration an element would be in correct position

Performance:
  - In-place algorithm, logical partition of array is done. Extra memory is not required for partition.
  - O(n^2) - Quadratic - Time Complexity
  - It will take 100 steps to sort 10 elements, 10,000 steps to sort 100 elements so on..
  - Algorithm degrades quickly as number of elements increases.
  - Stable Algorithm.

Stable vs Unstable Algorithm
  - Stable: Preserves relative ordering of duplicate items
    Ex: If an array has 2 elements with value, its ordering is unaltered.
  - Unstable: Does not preserve relative ordering of duplicate items
    Ex: If an array has 2 elements with value, its ordering is changed.

Selection Sort
  - Divides the array into sorted and unsorted partition
  - Grows the sorted partition from right to left
  - Traverse the elements of Unsorted partition and find the largest element
  - Swap the largest element with the last element

Performance:
  - In-place algorithm, logical partition of array is done. Extra memory is not required for partition.
  - O(n^2) - Quadratic - Time Complexity
  - It will take 100 steps to sort 10 elements, 10,000 steps to sort 100 elements so on..
  - Algorithm degrades quickly as number of elements increases.
  - Unstable Algorithm.
  
 Insertion Sort
  - Divides the array into sorted and unsorted partition
  - Grows the sorted partition from left to right
  - Starts by considering element at position 1 as element in sorted partition.
  - On Each iteration, first element from unsorted partition is taken and inserted into sorted partition.
  - We compare the value to be inserted with values in the sorted partition.
  - Position of insertion is determined by comparing values in the sorted partition against new element.
  - If new element is less than the elements in the sorted partition, elements are shifted in the sorted partition.
  
Implementation:
  - firstInsortedIndex = 1 -> Second element in the array.
 

Performance:
  - In-place algorithm, logical partition of array is done. Extra memory is not required for partition.
  - O(n^2) - Quadratic - Time Complexity
  - It will take 100 steps to sort 10 elements, 10,000 steps to sort 100 elements so on..
  - Algorithm degrades quickly as number of elements increases.
  - Unstable Algorithm.
  
Shell Sort
  - Variation of Insertion Sort
  - Insertion chooses which element to insert using a gap of 1
  - Shell sort starts out using larger gap value
  - As the alogorithm progresses, gap value is reduced
  - Last gap value is 1, at this point it is equivalent to insertion sort 
  - Algorithm does preliminary works using gap value greater than 1 and then it performs insertion sort
  - By the time we get to insertion sort array would be partialy sorted hence it takes less time.
  
Performance:
  - In-place algorithm, logical partition of array is done. Extra memory is not required for partition.
  - Time Complexity - Depends on the gap choosen. Worst case - O(n^2)
  - It requires less shifting
  - Unstable algorithm
  
Merge Sort
  - Divide and Conquer Algorithm
  - Recursive algorithm
  - Two Phases: Splitting and Merging
  - Splitting is logical, New arrays are not created. Splitting leads to faster sorting during merging.
  - Splitting Phase: 
    + Start with unsorted array, divide it into 2 arrays left array and right array.
    + Split the left and right arrays again.
    + Keep splitting until all arrays have one element each.
  - Merging Phase:
    + Merge left and right sub arrays into sorted array.
    + After first merge we will have a bunch of 2 element sorted array.
    + Then merge these sorted arrays to end up with bunch of 4 element sorted array.
    + Keep merging untill a single sorted array is formed

Performancs:
  - Not inplace, Uses temporary arrays
  - O(logn) - base 2 . We're repeatedly dividing the arrays into half during splitting phase
  - Stable Algorithm
    
Quick Sort
  - Divide and Conquer Algorithm
  - Uses a pivot element to partition the elements of an array.
  - Elements less than pivot to left and elements greater than pivot to right.
  - So that, post partition pivot will be in its correct position
  - Elements in left and right side need not be in sorted order
  - Process is repeated for left and right sub-arrays as well.
  - End of it, every element would end of becoming a pivot and all elements would be in its correct position

Implementation:
  - Consider first element as the pivot element.
  - i -> to traverse array from left to right, initially points to start of array
  - j -> traverse array from right to left, initially points to end of array
  - Traverse the array from right to left by comparing each element to the pivot till we find an element that is less than the pivot.
  - Once an element is found at position(j), replace an element at position(i) with new element.
  - Now same element would be present in position i & j
  - Now traverse the array from left to right by comparing each element to the pivot till we find an element that is greater than the pivot
  - Once an element is found at position(i) replace element at position (j) with new element.
  - Repeat the process untill i is less than j.
  - Once i and j overlaps, replace the element at position j with pivot. Now pivoy element would be in its correct position in the array.
  - At the end of the iteration, elements to the left of the pivot would be less than pivot and elements to the right would be greater than pivot.
  
Performancs:
  - Not inplace, Uses temporary arrays
  - O(logn) - base 2 . We're repeatedly partition the arrays into half during splitting phase
  - Better than mergesort
  - Unstable Algorithm
  - Time complexity depends on pivot choosen

Counting Sort: 
  - Make assumptions about the data
  - Assumes that all values are within a range
  - Only works with non-negative discrete values(Can't work with strings, floats)
  
Performancs:
  - Not an in-place algorithm
  - O(n) - Can be achieved since we are making assumption
  
Implmentation:
  - Takes minimum value in the array and maximum value in the array as input
  - First create the count array to count each values in the array , size would be (max value - min value)+1, 
    to hold all values in the range
  - Traverse the input array and count how many occurence of each value exists.
  - Figure out the position in count array and increment the value.
  - countArray[inputArray[i] - min]++; -> Increment the count of particular element in the array.
  - Once countArray is completely created, Write the values to inputArray based on count Array values.
  - Use Loop 1 for traversing elements in the count array and 1 Inner Loop for traversing the repeated elements in the array.
  - Decrement the count values in inner loop

Radix Sort:
  - Makes assumption about the data it is sorting
  - Assumes data has same radix and width.
  - Radix -> range of values of digit or alphabet.
  - Ex: Binary Digit - 2(0 and 1), Decimal - 10(0-9), English alphabet - 26(A-Z)
  - Width -> Number of digits/letters
  - Ex: 1234 - 4(Since it has 4 digits), Hello - 5 (Since it has 5 letters)
  - Sort based on each individual letter or digit position starting from the rightmost digit.
  - Stable sorting has to be used to preserve the order of previous sorting.
  
Performancs:
  - O(n) - Can be achieved since we are making assumption
  - Slower than O(nLogn) because of the overhead involved
  - In-place depends on the sort alorithm
  - Stable algorithm

Stable Counting Sort:
  - Requires some extra steps to make it stable
  - Count the number as normal Counting Sort
  - 
