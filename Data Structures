Data Structures are used to store and organize the data so that it can be used effeciently.

Algorithms - Steps to be performed for accomplishing a particular task.
Real time example: Steps involved in Preparing Tea.

Need for Big O Notation:

Same implementation can take different time when it is run on Super Computer and Normal Computer.
Hence for determing performance based on number of steps Big O Notation was introduced, where performance is measured by taking 
number of steps into account.

Big O Notation -
Determines performance of the data structures
Describes the complexity of the data structure
Tells us how well an algorithm scales as the input increases.
Worst case is used to determine the time complexity of the algorithm.

O(1) - Constant time - No matter how many elements u have in your data structures, Algorithm always perform same number of operations
O(logn)(base 2) - Logarithamic - Slows rises as the number of elements increases Ex: Binary Search
O(n) - Linear - Descreases the performance as the elements decreases. Ex: For Loop, While Loop
O(nlogn)(base 2) - n log-star-n Logarithamic - Slows rises as the number of elements increases Ex: Binary Search
O(n^2) - Quadratic - As the number of elements increase, performance becomes very very low. Ex: Loop within loop
O(c^n) - Exponential - Recusrive calls over n and loop over c in it.
O(n!) - Factorial - Looping over n and recursive call in the loop for (n-1) elements

Data Structures Performancen for average case: 
                Access    Search    Insert    Delete
Stack           O(n)      O(n)      O(1)      O(1)
Queue           O(n)      O(n)      O(1)      O(1)
Linked List     O(n)      O(n)      O(1)      O(1)
Hash Table      O(1)      O(1)      O(1)      O(1)
Binary Tree     O(logn)   O(logn)   O(logn)   O(logn)

Array:
Arrays are not dynamic data structure. 
Once created we cannot increase or decrease the size.
int intArray[] = new int[7]; - Integer Array which can hold max 7 elements starting from position 0.

Arrays in Memory:
  - Stored as one contigous block in memory.
  - Hence length has to specified while creating an Array.
  - Every element in an Array occupies same amount of space in memory.
  - In case of Object Array. Arrays will have only Object Reference. Hence same size.
  - If an array starts at memory address is x, and size of each element is y, then we get the position of ith element in the array.
    By using the formula x+i*y
  - Ex: Start Address of Array : 12, Element Size: 4
    Address of array[0] = 12+4*0 = 12
    Address of array[1] = 12+4*1 = 16
    Address of array[2] = 12+4*2 = 20
    Address of array[3] = 12+4*3 = 24
    Address of array[4] = 12+4*4 = 28
    
Performance of Array:

Operation                                                       Time Complexity
Retrieve with index                                             O(1) - Constant time                                                                      
Retrieve without index(We need to search for an element)        O(n) - Linear time
Adding an element to the full array                             O(n) - Linear time  
(Create a brand new Array that takes existing and new elements.)
Adding an element to the end of an array                        O(1) - Constant time
Insert/Update at specific location                              O(1) - Constant time
Deleting an element by setting it to null                       O(1) - Constant time
Deleting an element by shifting elements                        O(n) - Linar time

Sort Algorithms:

Bubble Sort 
  - Performance degrades quickly as number of elements grows.
  - Grows the sorted partition from right to left
Algorithm:
  - Larger value in an array bubbles up to the top on each iteration.
  - During each iteration, an element is compared with the next one and swaped if an element is greater than the next one.
  - End of each iteration an element would be in correct position

Performance:
  - In-place algorithm, logical partition of array is done. Extra memory is not required for partition.
  - O(n^2) - Quadratic - Time Complexity
  - It will take 100 steps to sort 10 elements, 10,000 steps to sort 100 elements so on..
  - Algorithm degrades quickly as number of elements increases.
  - Stable Algorithm.

Stable vs Unstable Algorithm
  - Stable: Preserves relative ordering of duplicate items
    Ex: If an array has 2 elements with value, its ordering is unaltered.
  - Unstable: Does not preserve relative ordering of duplicate items
    Ex: If an array has 2 elements with value, its ordering is changed.

Selection Sort
  - Divides the array into sorted and unsorted partition
  - Grows the sorted partition from right to left
  - Traverse the elements of Unsorted partition and find the largest element
  - Swap the largest element with the last element

Performance:
  - In-place algorithm, logical partition of array is done. Extra memory is not required for partition.
  - O(n^2) - Quadratic - Time Complexity
  - It will take 100 steps to sort 10 elements, 10,000 steps to sort 100 elements so on..
  - Algorithm degrades quickly as number of elements increases.
  - Unstable Algorithm.
  
  
 Insertion Sort
  - Divides the array into sorted and unsorted partition
  - Grows the sorted partition from left to right

Methods of Stack: LIFO - Last In First Out

push() - Adds an item to the top of a stack
pop() - Removes an item from the top of a stack
contains() - Checks if an element exists in the stack
access() - Pops all the element till an item is found

Methods of Queue: FIFO - First In First Out

enQueue - Inserts an element into a queue
deQueue - Removes an element into a queue
search - Search for an element in a queue
access


